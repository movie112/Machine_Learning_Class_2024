# Assignment 06

## 1. Problem Definition

### (1) Polynomial regression by least square problems

- data

$$
\{ (x_i, y_i) \}_{i=1}^n = \{ (x_1, y_1), (x_2, y_2), \cdots, (x_n, y_n) \}
$$

- model

$$
\hat{f}(\theta ; x) = \theta_0 x^0 + \theta_1 x^1 + \cdots + \theta_{p-1} x^{p-1}
$$

- model parameters

$$
\theta = (\theta_0, \theta_1, \cdots, \theta_{p-1})
$$

- residual

$$
\gamma_{i}(\theta) = y_i - \hat{f}(\theta ; x_i)
$$

- objective function

$$
\mathcal{L}(\theta) = \frac{1}{2 n} \sum_{i=1}^n \gamma_{i}^2(\theta)
$$

- solution

$$
\theta^* = \arg\min_{\theta} \mathcal{L}(\theta)
$$

### (2) Matrix representation for the polynomial regression

- problem definition in matrix representation

$$
A \, \theta = y
$$

$$
A =
\begin{bmatrix}
x_{1}^{0} & x_{1}^{1} & \cdots & x_{1}^{p-1} \\
x_{2}^{0} & x_{2}^{1} & \cdots & x_{2}^{p-1} \\
\vdots & \vdots & \ddots & \vdots \\
x_{n}^{0} & x_{n}^{1} & \cdots & x_{n}^{p-1}
\end{bmatrix},
\quad
\theta =
\begin{bmatrix}
\theta_{0} \\
\theta_{1} \\
\vdots \\
\theta_{p-1}
\end{bmatrix},
\quad
y =
\begin{bmatrix}
y_{1} \\
y_{2} \\
\vdots \\
y_{n}
\end{bmatrix}
$$

where $p \in \mathbb{N}$ denotes the power of the polynomial function

- objective function

$$
\mathcal{L}(\theta) = \frac{1}{2 n} \| A \, \theta - y \|_2^2 = \frac{1}{2 n} ( A \, \theta - y )^T ( A \, \theta - y ) = \frac{1}{2 n} ( \theta^T A^T - y^T ) ( A \, \theta - y ) 
$$

- solution

$$
\nabla \mathcal{L}(\theta^*) = \frac{1}{n} ( A^T A \theta^* - A^T y) = 0 
$$

#### (3) Matrix representation for the polynomial regression with regularization

- objective function

$$
\begin{align*}
\mathcal{L}(\theta) &= \frac{1}{2 n} \| A \, \theta - y \|_2^2 + \frac{\alpha}{2 n} \| \theta \|_2^2\\
&= \frac{1}{2 n} ( A \, \theta - y )^T ( A \, \theta - y ) + \frac{\alpha}{2 n} (\theta^T \theta)\\
&= \frac{1}{2 n} ( \theta^T A^T - y^T ) ( A \, \theta - y ) + \frac{\alpha}{2 n} (\theta^T \theta)\\
&= \frac{1}{2 n} ( \theta^T A^T A \, \theta - \theta^T A^T y - y^T A \, \theta + y^T y ) + \frac{\alpha}{2 n} (\theta^T \theta)\\ 
\end{align*}
$$

where $\alpha > 0$ in $\mathbb{R}$ is a control parameter for the regularization.

- solution

$$
\nabla \mathcal{L}(\theta^*) = \frac{1}{n} ( A^T A \theta^* - A^T y) + \frac{\alpha}{n} \theta^* = 0
$$

## 2. code completion

- complete `util.py` code
- run all the cells in the jupyter notebook
- make `git commit` for the `util.py` file in such a way that your working progress is effectively presented

## 3. submission

1. jupyter notebook source files [.ipynb] - complete the jupyter notebook with all the results
   - `06.ipynb`
2. jupyter notebook pdf files [.pdf] - export the complete jupyter notebook to HTML and then PDF
   - `06.pdf`
3. GitHub history pdf file [.pdf] - export the GitHub history of the utility python file to a pdf file
   - `06_history.pdf`
4. python files [.py] - complete the utility python file
   - `util.py`
